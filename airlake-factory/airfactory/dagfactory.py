import os
from typing import Optional,Dict, Any,List

import pendulum

from airflow import DAG

from airfactory.core.exception import DagFactoryConfigException
from airfactory.core.consts import DagFields,DefaultARGsFields
from airfactory.common.logger import LoggerMixing


class AirlakeDagFactory(LoggerMixing):
    def __init__(self, config_filepath: Optional[str] = None, config: Dict[str, Any] = None
    ) -> None:
        assert bool(config_filepath) ^ bool(
            config
        ), "Either `config_filepath` or `config` should be provided"
        if config_filepath:
            AirlakeDagFactory._validate_config_filepath(config_filepath=config_filepath)
            self.config: Dict[str, Any] = AirlakeDagFactory._load_config(
                config_filepath=config_filepath
            )
        if config:
            self.config: Dict[str, Any] = config

    def cleans_dags(self):
        """
        Clean old DAGs that are not on YAML config but were auto-generated through dag-factory

        :param globals: The globals() from the file used to generate DAGs. The dag_id
            must be passed into globals() for Airflow to import
        """
        dags: Dict[str, Any] = self.build_dags()

        # filter dags that exists in globals and is auto-generated by dag-factory
        dags_in_globals: Dict[str, Any] = {}
        for k, glb in globals.items():
            if isinstance(glb, DAG) and hasattr(glb, "is_dagfactory_auto_generated"):
                dags_in_globals[k] = glb

        # finding dags that doesn't exist anymore
        dags_to_remove: List[str] = list(set(dags_in_globals) - set(dags))
        # removing dags from DagBag
        for dag_to_remove in dags_to_remove:
            del globals[dag_to_remove]

    def generate_dags(self,globals: Dict[str, Any]):
        """
        Generates the DAGs based on the configuration provided.
        Returns:
            dags (Dict[str, Any]): A dictionary containing the generated DAGs.
        """
        dags: Dict[str, Any] = self.build_dags()
        self.register_dags(dags=dags, globals=globals())
    
    # pylint: disable=redefined-builtin
    @staticmethod
    def register_dags(dags: Dict[str, DAG], globals: Dict[str, Any]) -> None:
        """Adds `dags` to `globals` so Airflow can discover them.

        :param: dags: Dict of DAGs to be registered.
        :param globals: The globals() from the file used to generate DAGs. The dag_id
            must be passed into globals() for Airflow to import
        """
        for dag_id, dag in dags.items():
            globals[dag_id] = dag
            
    def compile_instance(self, conf: Dict[str, Any]) -> Dict[str, Any]:
        """Resolve datetime instance, add failure_callback and other stuff like k8s resources"""
        default_args = conf.get(DagFields.DefaultArgs, {})
        start_date = default_args.get(DefaultARGsFields.StartDate, None)
        if start_date:
            default_args[DefaultARGsFields.StartDate] = pendulum.parse(start_date)
        pass
    def _validate_config_filepath(self, config_filepath: str):
        if not os.path.isabs(config_filepath):
            raise DagFactoryConfigException(
                "DAG Factory `config_filepath` must be absolute path"
            )
    def build_dags(self) -> Dict[str, Any]:
        dags: Dict[str, Any] = {}
        for dag_id, dag_params in self.config.items():
            pass
        return dags
    

   